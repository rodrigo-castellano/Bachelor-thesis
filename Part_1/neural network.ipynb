{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>COSMIC RADIATION: deep learning</b>\n",
    "    \n",
    "rodrigoX: Contains 4 parameters\n",
    "    1. NALLParticlesTotal : Total number of particles generated by the event in the ground level.\n",
    "    2. MUTotal : Total number of muons.\n",
    "    3. ELTotal : Total number of electromagnetic particles.\n",
    "    4. Zenith : Zenith angle of the particle [degrees].\n",
    "    5. Energy : Particle energy [GeV].\n",
    "\n",
    "rodrigoY: contains the target\n",
    "    Labels: photon, proton, helium, nitrogen, iron.\n",
    "        the smallest number is assigned to photon (A=0) and the highest number to the heaviest particle, this is, iron (B=4).\n",
    "        \n",
    "        0==photon     1==proton    2==helium     3==nitrogen   4==iron \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To Save a session\n",
    "# import dill\n",
    "# import pickle\n",
    "# dill.dump_session('notebook_env.db') #esto es de la forma normal,solo de la otra forma no funciona con tensoflow\n",
    "# with open('basic_history.pickle', 'wb') as f:\n",
    "#     pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To restore a session\n",
    "# with open('basic_history.pickle', 'rb') as f:\n",
    "#     history = pickle.load(f)#para cargar una variable\n",
    "    \n",
    "#dill.load_session('basic_history.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e1fac477d50b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Load it back:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cosmic_radiation.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#to save the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#model.save('cosmic_radiation.model')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#Load it back:\n",
    "model = tf.keras.models.load_model('cosmic_radiation.model')\n",
    "#to save the model\n",
    "#model.save('cosmic_radiation.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave the dataset ready\n",
    "df_x = pd.read_fwf('XRodrigo.txt')\n",
    "df_x.columns = [\"NALLParticlesTotal\", \"MUTotal\", \"ELTotal\", \"Zenith\",\"Energy\"]\n",
    "df_y=pd.read_fwf('YRodrigo.txt')\n",
    "df_y.columns = [\"Particle\"]\n",
    "\n",
    "transpose=df_x.T\n",
    "transpose_y=df_y.T #Transpose to put them together\n",
    "df_tot = transpose.append(transpose_y)\n",
    "df_tot=df_tot.T.sample(frac=1).reset_index(drop=True)#este el el df completo y barajado\n",
    "\n",
    "df_y=df_tot[['Particle']]\n",
    "df_x=df_tot[[\"NALLParticlesTotal\", \"MUTotal\", \"ELTotal\", \"Zenith\",\"Energy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split and reescale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, random_state=0,test_size = 0.25)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train_np=y_train.to_numpy()\n",
    "y_test_np=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "hidden_layers=5\n",
    "for i in range(hidden_layers):\n",
    "       \n",
    "        model.add(tf.keras.layers.Dense(150, kernel_initializer='glorot_uniform', activation=tf.nn.relu))\n",
    "        # model.add(BatchNormalization())    use_bias=False,\n",
    "        # model.add(tf.keras.layers.Dropout(0.0))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(5, activation=tf.nn.softmax))\n",
    "\n",
    "# N_TRAIN=X_train.shape[0];BATCH_SIZE=128\n",
    "# STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
    "# lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay( 0.001,decay_steps=STEPS_PER_EPOCH*500,decay_rate=1,staircase=False)\n",
    "# #STEPS_PER_EPOCH*300-->The code above sets a schedules.InverseTimeDecay to hyperbolically decrease the learning rate to 1/2 of the base rate at 300 epochs, 1/3 at 600 epochs and so on.\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=optimizer , loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "#If I want to know the weights of a layer:\n",
    "#model.layers[1].get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31493 samples, validate on 10498 samples\n",
      "Epoch 1/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 1.1558 - accuracy: 0.5321 - val_loss: 0.8212 - val_accuracy: 0.7462\n",
      "Epoch 2/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.7201 - accuracy: 0.7497 - val_loss: 0.6362 - val_accuracy: 0.7269\n",
      "Epoch 3/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.5936 - accuracy: 0.8032 - val_loss: 0.5434 - val_accuracy: 0.8559\n",
      "Epoch 4/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.5147 - accuracy: 0.8327 - val_loss: 0.4961 - val_accuracy: 0.7790\n",
      "Epoch 5/500\n",
      "31493/31493 [==============================] - 3s 98us/sample - loss: 0.4581 - accuracy: 0.8476 - val_loss: 0.4045 - val_accuracy: 0.8902\n",
      "Epoch 6/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.4144 - accuracy: 0.8553 - val_loss: 0.4385 - val_accuracy: 0.7804\n",
      "Epoch 7/500\n",
      "31493/31493 [==============================] - 3s 92us/sample - loss: 0.3829 - accuracy: 0.8638 - val_loss: 0.3465 - val_accuracy: 0.8976\n",
      "Epoch 8/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.3576 - accuracy: 0.8719 - val_loss: 0.3731 - val_accuracy: 0.8180\n",
      "Epoch 9/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.3321 - accuracy: 0.8820 - val_loss: 0.2948 - val_accuracy: 0.9141\n",
      "Epoch 10/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.3228 - accuracy: 0.8835 - val_loss: 0.3311 - val_accuracy: 0.8384\n",
      "Epoch 11/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.3051 - accuracy: 0.8891 - val_loss: 0.3451 - val_accuracy: 0.8223\n",
      "Epoch 12/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.2929 - accuracy: 0.8922 - val_loss: 0.3217 - val_accuracy: 0.8366\n",
      "Epoch 13/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.2893 - accuracy: 0.8920 - val_loss: 0.2616 - val_accuracy: 0.9154\n",
      "Epoch 14/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.2745 - accuracy: 0.8979 - val_loss: 0.2717 - val_accuracy: 0.8931\n",
      "Epoch 15/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.2659 - accuracy: 0.9017 - val_loss: 0.4147 - val_accuracy: 0.8113\n",
      "Epoch 16/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.2587 - accuracy: 0.9009 - val_loss: 0.2847 - val_accuracy: 0.8812\n",
      "Epoch 17/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.2542 - accuracy: 0.9014 - val_loss: 0.2278 - val_accuracy: 0.9068\n",
      "Epoch 18/500\n",
      "31493/31493 [==============================] - 3s 93us/sample - loss: 0.2479 - accuracy: 0.9046 - val_loss: 0.2737 - val_accuracy: 0.9049\n",
      "Epoch 19/500\n",
      "31493/31493 [==============================] - 3s 94us/sample - loss: 0.2483 - accuracy: 0.9018 - val_loss: 0.2133 - val_accuracy: 0.9281\n",
      "Epoch 20/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.2412 - accuracy: 0.9079 - val_loss: 0.2051 - val_accuracy: 0.9199\n",
      "Epoch 21/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.2346 - accuracy: 0.9075 - val_loss: 0.2303 - val_accuracy: 0.8850\n",
      "Epoch 22/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.2179 - accuracy: 0.9146 - val_loss: 0.1967 - val_accuracy: 0.9300\n",
      "Epoch 23/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.2352 - accuracy: 0.9035 - val_loss: 0.2072 - val_accuracy: 0.9131\n",
      "Epoch 24/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.2404 - accuracy: 0.9023 - val_loss: 0.1974 - val_accuracy: 0.9299\n",
      "Epoch 25/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.2137 - accuracy: 0.9132 - val_loss: 0.1867 - val_accuracy: 0.9324\n",
      "Epoch 26/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.2204 - accuracy: 0.9113 - val_loss: 0.1732 - val_accuracy: 0.9474\n",
      "Epoch 27/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.2170 - accuracy: 0.9140 - val_loss: 0.1897 - val_accuracy: 0.9305\n",
      "Epoch 28/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.2031 - accuracy: 0.9158 - val_loss: 0.2589 - val_accuracy: 0.8726\n",
      "Epoch 29/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.2248 - accuracy: 0.9086 - val_loss: 0.1713 - val_accuracy: 0.9453\n",
      "Epoch 30/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.2056 - accuracy: 0.9171 - val_loss: 0.1758 - val_accuracy: 0.9247\n",
      "Epoch 31/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1888 - accuracy: 0.9220 - val_loss: 0.2767 - val_accuracy: 0.8821\n",
      "Epoch 32/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.2109 - accuracy: 0.9147 - val_loss: 0.3470 - val_accuracy: 0.8509\n",
      "Epoch 33/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1880 - accuracy: 0.9223 - val_loss: 0.1709 - val_accuracy: 0.9307\n",
      "Epoch 34/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1966 - accuracy: 0.9195 - val_loss: 0.1974 - val_accuracy: 0.9066\n",
      "Epoch 35/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1947 - accuracy: 0.9194 - val_loss: 0.1592 - val_accuracy: 0.9471\n",
      "Epoch 36/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1911 - accuracy: 0.9193 - val_loss: 0.1528 - val_accuracy: 0.9452\n",
      "Epoch 37/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1924 - accuracy: 0.9199 - val_loss: 0.2068 - val_accuracy: 0.9089\n",
      "Epoch 38/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1912 - accuracy: 0.9178 - val_loss: 0.3585 - val_accuracy: 0.8496\n",
      "Epoch 39/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1724 - accuracy: 0.9278 - val_loss: 0.1559 - val_accuracy: 0.9310\n",
      "Epoch 40/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.2085 - accuracy: 0.9150 - val_loss: 0.1657 - val_accuracy: 0.9321\n",
      "Epoch 41/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1866 - accuracy: 0.9207 - val_loss: 0.3058 - val_accuracy: 0.8674\n",
      "Epoch 42/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1800 - accuracy: 0.9239 - val_loss: 0.2870 - val_accuracy: 0.8834\n",
      "Epoch 43/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1830 - accuracy: 0.9240 - val_loss: 0.1701 - val_accuracy: 0.9159\n",
      "Epoch 44/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1911 - accuracy: 0.9222 - val_loss: 0.1567 - val_accuracy: 0.9273\n",
      "Epoch 45/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1778 - accuracy: 0.9260 - val_loss: 0.2941 - val_accuracy: 0.8822\n",
      "Epoch 46/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1608 - accuracy: 0.9330 - val_loss: 0.1584 - val_accuracy: 0.9228\n",
      "Epoch 47/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1721 - accuracy: 0.9255 - val_loss: 0.1433 - val_accuracy: 0.9486\n",
      "Epoch 48/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1696 - accuracy: 0.9287 - val_loss: 0.3069 - val_accuracy: 0.8635\n",
      "Epoch 49/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1732 - accuracy: 0.9278 - val_loss: 0.1645 - val_accuracy: 0.9147\n",
      "Epoch 50/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1818 - accuracy: 0.9208 - val_loss: 0.2232 - val_accuracy: 0.8984\n",
      "Epoch 51/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1677 - accuracy: 0.9267 - val_loss: 0.1467 - val_accuracy: 0.9414\n",
      "Epoch 52/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1760 - accuracy: 0.9254 - val_loss: 0.1437 - val_accuracy: 0.9339\n",
      "Epoch 53/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1570 - accuracy: 0.9332 - val_loss: 0.1489 - val_accuracy: 0.9399\n",
      "Epoch 54/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1645 - accuracy: 0.9300 - val_loss: 0.2913 - val_accuracy: 0.8725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1727 - accuracy: 0.9255 - val_loss: 0.1393 - val_accuracy: 0.9340\n",
      "Epoch 56/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1642 - accuracy: 0.9297 - val_loss: 0.1695 - val_accuracy: 0.9268\n",
      "Epoch 57/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1780 - accuracy: 0.9268 - val_loss: 0.1461 - val_accuracy: 0.9371\n",
      "Epoch 58/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1567 - accuracy: 0.9341 - val_loss: 0.1271 - val_accuracy: 0.9568\n",
      "Epoch 59/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1687 - accuracy: 0.9267 - val_loss: 0.1351 - val_accuracy: 0.9349\n",
      "Epoch 60/500\n",
      "31493/31493 [==============================] - 2s 75us/sample - loss: 0.1561 - accuracy: 0.9339 - val_loss: 0.1978 - val_accuracy: 0.9010\n",
      "Epoch 61/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1579 - accuracy: 0.9317 - val_loss: 0.1471 - val_accuracy: 0.9321\n",
      "Epoch 62/500\n",
      "31493/31493 [==============================] - 2s 74us/sample - loss: 0.1548 - accuracy: 0.9332 - val_loss: 0.1243 - val_accuracy: 0.9548\n",
      "Epoch 63/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1579 - accuracy: 0.9328 - val_loss: 0.2680 - val_accuracy: 0.8891\n",
      "Epoch 64/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1547 - accuracy: 0.9353 - val_loss: 0.1260 - val_accuracy: 0.9510\n",
      "Epoch 65/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1524 - accuracy: 0.9344 - val_loss: 0.1162 - val_accuracy: 0.9589\n",
      "Epoch 66/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.1573 - accuracy: 0.9338 - val_loss: 0.1829 - val_accuracy: 0.9108\n",
      "Epoch 67/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1509 - accuracy: 0.9339 - val_loss: 0.1478 - val_accuracy: 0.9394\n",
      "Epoch 68/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1560 - accuracy: 0.9333 - val_loss: 0.1394 - val_accuracy: 0.9375\n",
      "Epoch 69/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1446 - accuracy: 0.9380 - val_loss: 0.1194 - val_accuracy: 0.9556\n",
      "Epoch 70/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1465 - accuracy: 0.9365 - val_loss: 0.1192 - val_accuracy: 0.9565\n",
      "Epoch 71/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1685 - accuracy: 0.9271 - val_loss: 0.1790 - val_accuracy: 0.9080\n",
      "Epoch 72/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1427 - accuracy: 0.9390 - val_loss: 0.1483 - val_accuracy: 0.9240\n",
      "Epoch 73/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1601 - accuracy: 0.9301 - val_loss: 0.2634 - val_accuracy: 0.8946\n",
      "Epoch 74/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1553 - accuracy: 0.9331 - val_loss: 0.1358 - val_accuracy: 0.9416\n",
      "Epoch 75/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1475 - accuracy: 0.9358 - val_loss: 0.1175 - val_accuracy: 0.9563\n",
      "Epoch 76/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1461 - accuracy: 0.9362 - val_loss: 0.1200 - val_accuracy: 0.9569\n",
      "Epoch 77/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.1435 - accuracy: 0.9378 - val_loss: 0.1914 - val_accuracy: 0.9436\n",
      "Epoch 78/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1446 - accuracy: 0.9364 - val_loss: 0.1157 - val_accuracy: 0.9487\n",
      "Epoch 79/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1412 - accuracy: 0.9379 - val_loss: 0.4849 - val_accuracy: 0.8529\n",
      "Epoch 80/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1566 - accuracy: 0.9325 - val_loss: 0.1273 - val_accuracy: 0.9403\n",
      "Epoch 81/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1407 - accuracy: 0.9378 - val_loss: 0.1822 - val_accuracy: 0.9144\n",
      "Epoch 82/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1373 - accuracy: 0.9400 - val_loss: 0.1160 - val_accuracy: 0.9548\n",
      "Epoch 83/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1419 - accuracy: 0.9392 - val_loss: 0.1115 - val_accuracy: 0.9544\n",
      "Epoch 84/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1367 - accuracy: 0.9404 - val_loss: 0.2038 - val_accuracy: 0.9061\n",
      "Epoch 85/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1447 - accuracy: 0.9347 - val_loss: 0.1139 - val_accuracy: 0.9499\n",
      "Epoch 86/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1502 - accuracy: 0.9370 - val_loss: 0.1544 - val_accuracy: 0.9189\n",
      "Epoch 87/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1384 - accuracy: 0.9388 - val_loss: 0.1252 - val_accuracy: 0.9509\n",
      "Epoch 88/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1502 - accuracy: 0.9361 - val_loss: 0.1195 - val_accuracy: 0.9552\n",
      "Epoch 89/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1396 - accuracy: 0.9405 - val_loss: 0.1800 - val_accuracy: 0.9081\n",
      "Epoch 90/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1381 - accuracy: 0.9392 - val_loss: 0.1124 - val_accuracy: 0.9528\n",
      "Epoch 91/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1320 - accuracy: 0.9410 - val_loss: 0.1224 - val_accuracy: 0.9449\n",
      "Epoch 92/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1514 - accuracy: 0.9372 - val_loss: 0.1328 - val_accuracy: 0.9328\n",
      "Epoch 93/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1400 - accuracy: 0.9378 - val_loss: 0.1291 - val_accuracy: 0.9332\n",
      "Epoch 94/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1297 - accuracy: 0.9442 - val_loss: 0.1060 - val_accuracy: 0.9600\n",
      "Epoch 95/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1280 - accuracy: 0.9457 - val_loss: 0.1064 - val_accuracy: 0.9608\n",
      "Epoch 96/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1470 - accuracy: 0.9410 - val_loss: 0.1050 - val_accuracy: 0.9568\n",
      "Epoch 97/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1217 - accuracy: 0.9464 - val_loss: 0.1332 - val_accuracy: 0.9431\n",
      "Epoch 98/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1345 - accuracy: 0.9406 - val_loss: 0.1137 - val_accuracy: 0.9493\n",
      "Epoch 99/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1311 - accuracy: 0.9426 - val_loss: 0.1078 - val_accuracy: 0.9490\n",
      "Epoch 100/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.1297 - accuracy: 0.9434 - val_loss: 0.0994 - val_accuracy: 0.9614\n",
      "Epoch 101/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1266 - accuracy: 0.9435 - val_loss: 0.1211 - val_accuracy: 0.9459\n",
      "Epoch 102/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1335 - accuracy: 0.9411 - val_loss: 0.1906 - val_accuracy: 0.9084\n",
      "Epoch 103/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1348 - accuracy: 0.9407 - val_loss: 0.1315 - val_accuracy: 0.9343\n",
      "Epoch 104/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1436 - accuracy: 0.9381 - val_loss: 0.1192 - val_accuracy: 0.9523\n",
      "Epoch 105/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1312 - accuracy: 0.9440 - val_loss: 0.2820 - val_accuracy: 0.8899\n",
      "Epoch 106/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1366 - accuracy: 0.9423 - val_loss: 0.1590 - val_accuracy: 0.9157\n",
      "Epoch 107/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1296 - accuracy: 0.9421 - val_loss: 0.3367 - val_accuracy: 0.8735\n",
      "Epoch 108/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1226 - accuracy: 0.9452 - val_loss: 0.1416 - val_accuracy: 0.9307\n",
      "Epoch 109/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1276 - accuracy: 0.9452 - val_loss: 0.1005 - val_accuracy: 0.9585\n",
      "Epoch 110/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.1234 - accuracy: 0.9454 - val_loss: 0.1722 - val_accuracy: 0.9139\n",
      "Epoch 111/500\n",
      "31493/31493 [==============================] - 3s 95us/sample - loss: 0.1333 - accuracy: 0.9416 - val_loss: 0.1071 - val_accuracy: 0.9524\n",
      "Epoch 112/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1257 - accuracy: 0.9437 - val_loss: 0.0949 - val_accuracy: 0.9608\n",
      "Epoch 113/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1254 - accuracy: 0.9456 - val_loss: 0.1011 - val_accuracy: 0.9552\n",
      "Epoch 114/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1243 - accuracy: 0.9472 - val_loss: 0.1010 - val_accuracy: 0.9626\n",
      "Epoch 115/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1257 - accuracy: 0.9438 - val_loss: 0.0979 - val_accuracy: 0.9566\n",
      "Epoch 116/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1252 - accuracy: 0.9461 - val_loss: 0.2458 - val_accuracy: 0.9044\n",
      "Epoch 117/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1238 - accuracy: 0.9456 - val_loss: 0.0972 - val_accuracy: 0.9588\n",
      "Epoch 118/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1284 - accuracy: 0.9436 - val_loss: 0.1107 - val_accuracy: 0.9473\n",
      "Epoch 119/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1331 - accuracy: 0.9404 - val_loss: 0.1342 - val_accuracy: 0.9402\n",
      "Epoch 120/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1267 - accuracy: 0.9434 - val_loss: 0.0984 - val_accuracy: 0.9641\n",
      "Epoch 121/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1227 - accuracy: 0.9479 - val_loss: 0.1084 - val_accuracy: 0.9545\n",
      "Epoch 122/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1228 - accuracy: 0.9468 - val_loss: 0.1092 - val_accuracy: 0.9503\n",
      "Epoch 123/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1252 - accuracy: 0.9455 - val_loss: 0.1167 - val_accuracy: 0.9418\n",
      "Epoch 124/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1246 - accuracy: 0.9462 - val_loss: 0.1080 - val_accuracy: 0.9581\n",
      "Epoch 125/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1252 - accuracy: 0.9436 - val_loss: 0.1071 - val_accuracy: 0.9541\n",
      "Epoch 126/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1226 - accuracy: 0.9484 - val_loss: 0.0999 - val_accuracy: 0.9551\n",
      "Epoch 127/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1258 - accuracy: 0.9471 - val_loss: 0.1231 - val_accuracy: 0.9411\n",
      "Epoch 128/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1221 - accuracy: 0.9460 - val_loss: 0.1097 - val_accuracy: 0.9473\n",
      "Epoch 129/500\n",
      "31493/31493 [==============================] - 2s 75us/sample - loss: 0.1278 - accuracy: 0.9463 - val_loss: 0.1004 - val_accuracy: 0.9516\n",
      "Epoch 130/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1280 - accuracy: 0.9470 - val_loss: 0.1654 - val_accuracy: 0.9447\n",
      "Epoch 131/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1310 - accuracy: 0.9454 - val_loss: 0.1433 - val_accuracy: 0.9250\n",
      "Epoch 132/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1190 - accuracy: 0.9485 - val_loss: 0.0878 - val_accuracy: 0.9668\n",
      "Epoch 133/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1201 - accuracy: 0.9483 - val_loss: 0.1082 - val_accuracy: 0.9502\n",
      "Epoch 134/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1401 - accuracy: 0.9471 - val_loss: 0.0897 - val_accuracy: 0.9699\n",
      "Epoch 135/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1150 - accuracy: 0.9493 - val_loss: 0.1150 - val_accuracy: 0.9412\n",
      "Epoch 136/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1278 - accuracy: 0.9446 - val_loss: 0.0930 - val_accuracy: 0.9617\n",
      "Epoch 137/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1162 - accuracy: 0.9461 - val_loss: 0.1073 - val_accuracy: 0.9442\n",
      "Epoch 138/500\n",
      "31493/31493 [==============================] - 2s 75us/sample - loss: 0.1177 - accuracy: 0.9477 - val_loss: 0.0946 - val_accuracy: 0.9649\n",
      "Epoch 139/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1343 - accuracy: 0.9423 - val_loss: 0.0976 - val_accuracy: 0.9563\n",
      "Epoch 140/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1153 - accuracy: 0.9489 - val_loss: 0.1122 - val_accuracy: 0.9408\n",
      "Epoch 141/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1165 - accuracy: 0.9479 - val_loss: 0.0913 - val_accuracy: 0.9637\n",
      "Epoch 142/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1180 - accuracy: 0.9474 - val_loss: 0.2507 - val_accuracy: 0.8926\n",
      "Epoch 143/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1193 - accuracy: 0.9463 - val_loss: 0.1361 - val_accuracy: 0.9350\n",
      "Epoch 144/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1205 - accuracy: 0.9474 - val_loss: 0.2498 - val_accuracy: 0.8953\n",
      "Epoch 145/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1146 - accuracy: 0.9489 - val_loss: 0.1014 - val_accuracy: 0.9580\n",
      "Epoch 146/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1148 - accuracy: 0.9494 - val_loss: 0.3451 - val_accuracy: 0.8844\n",
      "Epoch 147/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.1248 - accuracy: 0.9472 - val_loss: 0.1022 - val_accuracy: 0.9605\n",
      "Epoch 148/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1145 - accuracy: 0.9482 - val_loss: 0.1815 - val_accuracy: 0.9196\n",
      "Epoch 149/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1086 - accuracy: 0.9517 - val_loss: 0.0908 - val_accuracy: 0.9663\n",
      "Epoch 150/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1186 - accuracy: 0.9501 - val_loss: 0.0932 - val_accuracy: 0.9609\n",
      "Epoch 151/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1147 - accuracy: 0.9487 - val_loss: 0.2712 - val_accuracy: 0.8962\n",
      "Epoch 152/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1136 - accuracy: 0.9489 - val_loss: 0.1369 - val_accuracy: 0.9303\n",
      "Epoch 153/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1148 - accuracy: 0.9500 - val_loss: 0.0838 - val_accuracy: 0.9689\n",
      "Epoch 154/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1114 - accuracy: 0.9508 - val_loss: 0.0929 - val_accuracy: 0.9613\n",
      "Epoch 155/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1145 - accuracy: 0.9502 - val_loss: 0.1257 - val_accuracy: 0.9327\n",
      "Epoch 156/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1180 - accuracy: 0.9489 - val_loss: 0.1019 - val_accuracy: 0.9573\n",
      "Epoch 157/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1047 - accuracy: 0.9526 - val_loss: 0.1132 - val_accuracy: 0.9448\n",
      "Epoch 158/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.1112 - accuracy: 0.9519 - val_loss: 0.1015 - val_accuracy: 0.9520\n",
      "Epoch 159/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1176 - accuracy: 0.9504 - val_loss: 0.0921 - val_accuracy: 0.9595\n",
      "Epoch 160/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1110 - accuracy: 0.9513 - val_loss: 0.0866 - val_accuracy: 0.9637\n",
      "Epoch 161/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1067 - accuracy: 0.9521 - val_loss: 0.0896 - val_accuracy: 0.9597\n",
      "Epoch 162/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1158 - accuracy: 0.9492 - val_loss: 0.1196 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1224 - accuracy: 0.9490 - val_loss: 0.1004 - val_accuracy: 0.9556\n",
      "Epoch 164/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1069 - accuracy: 0.9521 - val_loss: 0.1037 - val_accuracy: 0.9468\n",
      "Epoch 165/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1327 - accuracy: 0.9422 - val_loss: 0.0936 - val_accuracy: 0.9601\n",
      "Epoch 166/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1029 - accuracy: 0.9542 - val_loss: 0.0953 - val_accuracy: 0.9590\n",
      "Epoch 167/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1145 - accuracy: 0.9520 - val_loss: 0.1190 - val_accuracy: 0.9431\n",
      "Epoch 168/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1057 - accuracy: 0.9523 - val_loss: 0.1051 - val_accuracy: 0.9534\n",
      "Epoch 169/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1082 - accuracy: 0.9521 - val_loss: 0.0884 - val_accuracy: 0.9648\n",
      "Epoch 170/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1131 - accuracy: 0.9529 - val_loss: 0.1048 - val_accuracy: 0.9492\n",
      "Epoch 171/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1104 - accuracy: 0.9525 - val_loss: 0.0904 - val_accuracy: 0.9645\n",
      "Epoch 172/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1150 - accuracy: 0.9488 - val_loss: 0.0878 - val_accuracy: 0.9621\n",
      "Epoch 173/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1065 - accuracy: 0.9541 - val_loss: 0.0934 - val_accuracy: 0.9571\n",
      "Epoch 174/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1165 - accuracy: 0.9496 - val_loss: 0.0964 - val_accuracy: 0.9561\n",
      "Epoch 175/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1009 - accuracy: 0.9555 - val_loss: 0.1626 - val_accuracy: 0.9245\n",
      "Epoch 176/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1048 - accuracy: 0.9531 - val_loss: 0.0988 - val_accuracy: 0.9514\n",
      "Epoch 177/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1117 - accuracy: 0.9500 - val_loss: 0.0967 - val_accuracy: 0.9561\n",
      "Epoch 178/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1075 - accuracy: 0.9526 - val_loss: 0.1166 - val_accuracy: 0.9489\n",
      "Epoch 179/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1079 - accuracy: 0.9534 - val_loss: 0.1121 - val_accuracy: 0.94270.1082 - accuracy: \n",
      "Epoch 180/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1127 - accuracy: 0.9511 - val_loss: 0.0904 - val_accuracy: 0.9632\n",
      "Epoch 181/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1085 - accuracy: 0.9508 - val_loss: 0.0916 - val_accuracy: 0.9612\n",
      "Epoch 182/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1099 - accuracy: 0.9521 - val_loss: 0.4044 - val_accuracy: 0.8834\n",
      "Epoch 183/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1057 - accuracy: 0.9532 - val_loss: 0.1744 - val_accuracy: 0.9213\n",
      "Epoch 184/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1098 - accuracy: 0.9518 - val_loss: 0.1732 - val_accuracy: 0.9195\n",
      "Epoch 185/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1046 - accuracy: 0.9535 - val_loss: 0.0907 - val_accuracy: 0.9609\n",
      "Epoch 186/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.1159 - accuracy: 0.9494 - val_loss: 0.1220 - val_accuracy: 0.9331\n",
      "Epoch 187/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1053 - accuracy: 0.9535 - val_loss: 0.1295 - val_accuracy: 0.9344\n",
      "Epoch 188/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1057 - accuracy: 0.9524 - val_loss: 0.1032 - val_accuracy: 0.9529\n",
      "Epoch 189/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1080 - accuracy: 0.9531 - val_loss: 0.0883 - val_accuracy: 0.9636\n",
      "Epoch 190/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.1069 - accuracy: 0.9518 - val_loss: 0.0870 - val_accuracy: 0.9611\n",
      "Epoch 191/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1116 - accuracy: 0.9520 - val_loss: 0.1062 - val_accuracy: 0.9507\n",
      "Epoch 192/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1065 - accuracy: 0.9531 - val_loss: 0.0959 - val_accuracy: 0.9503\n",
      "Epoch 193/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1026 - accuracy: 0.9545 - val_loss: 0.1416 - val_accuracy: 0.9317\n",
      "Epoch 194/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1095 - accuracy: 0.9520 - val_loss: 0.1881 - val_accuracy: 0.9175\n",
      "Epoch 195/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1003 - accuracy: 0.9557 - val_loss: 0.0953 - val_accuracy: 0.9539\n",
      "Epoch 196/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1054 - accuracy: 0.9537 - val_loss: 0.0955 - val_accuracy: 0.9588\n",
      "Epoch 197/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1056 - accuracy: 0.9541 - val_loss: 0.0973 - val_accuracy: 0.9521\n",
      "Epoch 198/500\n",
      "31493/31493 [==============================] - 3s 94us/sample - loss: 0.1041 - accuracy: 0.9542 - val_loss: 0.0976 - val_accuracy: 0.9536\n",
      "Epoch 199/500\n",
      "31493/31493 [==============================] - 3s 100us/sample - loss: 0.1003 - accuracy: 0.9554 - val_loss: 0.0836 - val_accuracy: 0.9665\n",
      "Epoch 200/500\n",
      "31493/31493 [==============================] - 4s 112us/sample - loss: 0.1074 - accuracy: 0.9536 - val_loss: 0.1263 - val_accuracy: 0.9367\n",
      "Epoch 201/500\n",
      "31493/31493 [==============================] - 3s 93us/sample - loss: 0.0983 - accuracy: 0.9560 - val_loss: 0.1269 - val_accuracy: 0.9435\n",
      "Epoch 202/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1055 - accuracy: 0.9533 - val_loss: 0.1247 - val_accuracy: 0.9370\n",
      "Epoch 203/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1041 - accuracy: 0.9538 - val_loss: 0.0972 - val_accuracy: 0.9518\n",
      "Epoch 204/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1155 - accuracy: 0.9539 - val_loss: 0.1555 - val_accuracy: 0.9271\n",
      "Epoch 205/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0946 - accuracy: 0.9589 - val_loss: 0.0790 - val_accuracy: 0.9669\n",
      "Epoch 206/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1081 - accuracy: 0.9539 - val_loss: 0.0791 - val_accuracy: 0.9684\n",
      "Epoch 207/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1026 - accuracy: 0.9541 - val_loss: 0.0789 - val_accuracy: 0.9681\n",
      "Epoch 208/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1033 - accuracy: 0.9536 - val_loss: 0.1005 - val_accuracy: 0.9491\n",
      "Epoch 209/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0969 - accuracy: 0.9561 - val_loss: 0.0812 - val_accuracy: 0.9631\n",
      "Epoch 210/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.1020 - accuracy: 0.9536 - val_loss: 0.2440 - val_accuracy: 0.9064\n",
      "Epoch 211/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0981 - accuracy: 0.9561 - val_loss: 0.0960 - val_accuracy: 0.9541\n",
      "Epoch 212/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.1007 - accuracy: 0.9563 - val_loss: 0.1447 - val_accuracy: 0.9341\n",
      "Epoch 213/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.1064 - accuracy: 0.9541 - val_loss: 0.1993 - val_accuracy: 0.9114\n",
      "Epoch 214/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0984 - accuracy: 0.9556 - val_loss: 0.1253 - val_accuracy: 0.9368\n",
      "Epoch 215/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.1059 - accuracy: 0.9541 - val_loss: 0.2204 - val_accuracy: 0.9086\n",
      "Epoch 216/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1050 - accuracy: 0.9544 - val_loss: 0.1462 - val_accuracy: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.1036 - accuracy: 0.9541 - val_loss: 0.1054 - val_accuracy: 0.9452\n",
      "Epoch 218/500\n",
      "31493/31493 [==============================] - 3s 95us/sample - loss: 0.0974 - accuracy: 0.9575 - val_loss: 0.0779 - val_accuracy: 0.9686\n",
      "Epoch 219/500\n",
      "31493/31493 [==============================] - 3s 95us/sample - loss: 0.1039 - accuracy: 0.9554 - val_loss: 0.1175 - val_accuracy: 0.9454\n",
      "Epoch 220/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1026 - accuracy: 0.9546 - val_loss: 0.0847 - val_accuracy: 0.9643\n",
      "Epoch 221/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1033 - accuracy: 0.9539 - val_loss: 0.2999 - val_accuracy: 0.8959\n",
      "Epoch 222/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1037 - accuracy: 0.9540 - val_loss: 0.0965 - val_accuracy: 0.9550\n",
      "Epoch 223/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0990 - accuracy: 0.9565 - val_loss: 0.0890 - val_accuracy: 0.9588\n",
      "Epoch 224/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0976 - accuracy: 0.9575 - val_loss: 0.1086 - val_accuracy: 0.9468\n",
      "Epoch 225/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1060 - accuracy: 0.9539 - val_loss: 0.1095 - val_accuracy: 0.9445\n",
      "Epoch 226/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1012 - accuracy: 0.9565 - val_loss: 0.0922 - val_accuracy: 0.9570\n",
      "Epoch 227/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0943 - accuracy: 0.9574 - val_loss: 0.0819 - val_accuracy: 0.9645\n",
      "Epoch 228/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1048 - accuracy: 0.9549 - val_loss: 0.0826 - val_accuracy: 0.9610\n",
      "Epoch 229/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.1017 - accuracy: 0.9552 - val_loss: 0.0748 - val_accuracy: 0.9689\n",
      "Epoch 230/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.1031 - accuracy: 0.9548 - val_loss: 0.0995 - val_accuracy: 0.9512\n",
      "Epoch 231/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0927 - accuracy: 0.9586 - val_loss: 0.0987 - val_accuracy: 0.9498\n",
      "Epoch 232/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1049 - accuracy: 0.9528 - val_loss: 0.0947 - val_accuracy: 0.9564\n",
      "Epoch 233/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1023 - accuracy: 0.9540 - val_loss: 0.1303 - val_accuracy: 0.9339\n",
      "Epoch 234/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0926 - accuracy: 0.9578 - val_loss: 0.0837 - val_accuracy: 0.9667\n",
      "Epoch 235/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1027 - accuracy: 0.9538 - val_loss: 0.0813 - val_accuracy: 0.9642\n",
      "Epoch 236/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0963 - accuracy: 0.9570 - val_loss: 0.1166 - val_accuracy: 0.9386\n",
      "Epoch 237/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0955 - accuracy: 0.9573 - val_loss: 0.0755 - val_accuracy: 0.9685\n",
      "Epoch 238/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0982 - accuracy: 0.9551 - val_loss: 0.0763 - val_accuracy: 0.9689\n",
      "Epoch 239/500\n",
      "31493/31493 [==============================] - 3s 79us/sample - loss: 0.1005 - accuracy: 0.9565 - val_loss: 0.0857 - val_accuracy: 0.9636\n",
      "Epoch 240/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.1002 - accuracy: 0.9550 - val_loss: 0.0910 - val_accuracy: 0.9604\n",
      "Epoch 241/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0960 - accuracy: 0.9565 - val_loss: 0.1241 - val_accuracy: 0.9340\n",
      "Epoch 242/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0938 - accuracy: 0.9571 - val_loss: 0.0744 - val_accuracy: 0.9674\n",
      "Epoch 243/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1005 - accuracy: 0.9559 - val_loss: 0.0798 - val_accuracy: 0.9669\n",
      "Epoch 244/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0959 - accuracy: 0.9577 - val_loss: 0.0822 - val_accuracy: 0.9664\n",
      "Epoch 245/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0996 - accuracy: 0.9553 - val_loss: 0.1319 - val_accuracy: 0.9338\n",
      "Epoch 246/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0982 - accuracy: 0.9569 - val_loss: 0.1502 - val_accuracy: 0.9259\n",
      "Epoch 247/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0962 - accuracy: 0.9586 - val_loss: 0.0857 - val_accuracy: 0.9568\n",
      "Epoch 248/500\n",
      "31493/31493 [==============================] - 3s 79us/sample - loss: 0.0928 - accuracy: 0.9581 - val_loss: 0.0895 - val_accuracy: 0.9594\n",
      "Epoch 249/500\n",
      "31493/31493 [==============================] - 3s 79us/sample - loss: 0.0985 - accuracy: 0.9575 - val_loss: 0.1038 - val_accuracy: 0.9578\n",
      "Epoch 250/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0930 - accuracy: 0.9593 - val_loss: 0.0779 - val_accuracy: 0.9685\n",
      "Epoch 251/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1003 - accuracy: 0.9550 - val_loss: 0.1047 - val_accuracy: 0.9465\n",
      "Epoch 252/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0965 - accuracy: 0.9580 - val_loss: 0.0769 - val_accuracy: 0.9683\n",
      "Epoch 253/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0958 - accuracy: 0.9576 - val_loss: 0.0919 - val_accuracy: 0.9536\n",
      "Epoch 254/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0923 - accuracy: 0.9596 - val_loss: 0.1891 - val_accuracy: 0.9187\n",
      "Epoch 255/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0951 - accuracy: 0.9577 - val_loss: 0.1118 - val_accuracy: 0.9422\n",
      "Epoch 256/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0982 - accuracy: 0.9546 - val_loss: 0.0827 - val_accuracy: 0.9651\n",
      "Epoch 257/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0938 - accuracy: 0.9567 - val_loss: 0.0970 - val_accuracy: 0.9516\n",
      "Epoch 258/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0912 - accuracy: 0.9600 - val_loss: 0.1005 - val_accuracy: 0.9511\n",
      "Epoch 259/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0951 - accuracy: 0.9582 - val_loss: 0.0810 - val_accuracy: 0.9649\n",
      "Epoch 260/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.1015 - accuracy: 0.9555 - val_loss: 0.1048 - val_accuracy: 0.9482\n",
      "Epoch 261/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0973 - accuracy: 0.9576 - val_loss: 0.0864 - val_accuracy: 0.9591\n",
      "Epoch 262/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0947 - accuracy: 0.9594 - val_loss: 0.0789 - val_accuracy: 0.9682\n",
      "Epoch 263/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0966 - accuracy: 0.9578 - val_loss: 0.0823 - val_accuracy: 0.9616\n",
      "Epoch 264/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0943 - accuracy: 0.9576 - val_loss: 0.0821 - val_accuracy: 0.9639\n",
      "Epoch 265/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.1043 - accuracy: 0.9550 - val_loss: 0.1128 - val_accuracy: 0.9418\n",
      "Epoch 266/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0951 - accuracy: 0.9581 - val_loss: 0.0823 - val_accuracy: 0.9657\n",
      "Epoch 267/500\n",
      "31493/31493 [==============================] - 3s 79us/sample - loss: 0.0971 - accuracy: 0.9584 - val_loss: 0.0850 - val_accuracy: 0.9610\n",
      "Epoch 268/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1017 - accuracy: 0.9550 - val_loss: 0.0984 - val_accuracy: 0.9481\n",
      "Epoch 269/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0968 - accuracy: 0.9557 - val_loss: 0.1558 - val_accuracy: 0.9318\n",
      "Epoch 270/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0968 - accuracy: 0.9553 - val_loss: 0.0751 - val_accuracy: 0.9669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.1042 - accuracy: 0.9535 - val_loss: 0.0786 - val_accuracy: 0.9682\n",
      "Epoch 272/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0975 - accuracy: 0.9558 - val_loss: 0.0825 - val_accuracy: 0.9648\n",
      "Epoch 273/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0946 - accuracy: 0.9587 - val_loss: 0.1171 - val_accuracy: 0.9389\n",
      "Epoch 274/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0943 - accuracy: 0.9569 - val_loss: 0.1014 - val_accuracy: 0.9493\n",
      "Epoch 275/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0976 - accuracy: 0.9573 - val_loss: 0.0824 - val_accuracy: 0.9638\n",
      "Epoch 276/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0957 - accuracy: 0.9569 - val_loss: 0.0889 - val_accuracy: 0.9539\n",
      "Epoch 277/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0905 - accuracy: 0.9585 - val_loss: 0.0757 - val_accuracy: 0.9701\n",
      "Epoch 278/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0998 - accuracy: 0.9565 - val_loss: 0.0916 - val_accuracy: 0.9586\n",
      "Epoch 279/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0934 - accuracy: 0.9578 - val_loss: 0.0727 - val_accuracy: 0.9699\n",
      "Epoch 280/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.0915 - accuracy: 0.9585 - val_loss: 0.1451 - val_accuracy: 0.9285\n",
      "Epoch 281/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0924 - accuracy: 0.9581 - val_loss: 0.1075 - val_accuracy: 0.9452\n",
      "Epoch 282/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0908 - accuracy: 0.9601 - val_loss: 0.1046 - val_accuracy: 0.9467\n",
      "Epoch 283/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0968 - accuracy: 0.9569 - val_loss: 0.0904 - val_accuracy: 0.9583\n",
      "Epoch 284/500\n",
      "31493/31493 [==============================] - 3s 94us/sample - loss: 0.0886 - accuracy: 0.9602 - val_loss: 0.1354 - val_accuracy: 0.9357\n",
      "Epoch 285/500\n",
      "31493/31493 [==============================] - 3s 107us/sample - loss: 0.0915 - accuracy: 0.9590 - val_loss: 0.0995 - val_accuracy: 0.9497\n",
      "Epoch 286/500\n",
      "31493/31493 [==============================] - 3s 97us/sample - loss: 0.0920 - accuracy: 0.9587 - val_loss: 0.0778 - val_accuracy: 0.9660\n",
      "Epoch 287/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0904 - accuracy: 0.9590 - val_loss: 0.0798 - val_accuracy: 0.9652\n",
      "Epoch 288/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0905 - accuracy: 0.9603 - val_loss: 0.0896 - val_accuracy: 0.9626\n",
      "Epoch 289/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0966 - accuracy: 0.9583 - val_loss: 0.0871 - val_accuracy: 0.9582\n",
      "Epoch 290/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0923 - accuracy: 0.9582 - val_loss: 0.0864 - val_accuracy: 0.9579\n",
      "Epoch 291/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.1000 - accuracy: 0.9564 - val_loss: 0.1367 - val_accuracy: 0.9313\n",
      "Epoch 292/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0957 - accuracy: 0.9573 - val_loss: 0.1047 - val_accuracy: 0.9448\n",
      "Epoch 293/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0944 - accuracy: 0.9579 - val_loss: 0.1142 - val_accuracy: 0.9398\n",
      "Epoch 294/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0909 - accuracy: 0.9597 - val_loss: 0.1033 - val_accuracy: 0.9505\n",
      "Epoch 295/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0965 - accuracy: 0.9576 - val_loss: 0.1096 - val_accuracy: 0.9446\n",
      "Epoch 296/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0846 - accuracy: 0.9620 - val_loss: 0.0710 - val_accuracy: 0.9710\n",
      "Epoch 297/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0896 - accuracy: 0.9597 - val_loss: 0.0725 - val_accuracy: 0.9689\n",
      "Epoch 298/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0913 - accuracy: 0.9591 - val_loss: 0.0955 - val_accuracy: 0.9553\n",
      "Epoch 299/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0920 - accuracy: 0.9598 - val_loss: 0.0755 - val_accuracy: 0.9668\n",
      "Epoch 300/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0916 - accuracy: 0.9599 - val_loss: 0.0742 - val_accuracy: 0.9676\n",
      "Epoch 301/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0914 - accuracy: 0.9586 - val_loss: 0.0914 - val_accuracy: 0.9551\n",
      "Epoch 302/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0930 - accuracy: 0.9588 - val_loss: 0.0793 - val_accuracy: 0.9634\n",
      "Epoch 303/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0889 - accuracy: 0.9602 - val_loss: 0.0753 - val_accuracy: 0.9683\n",
      "Epoch 304/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0939 - accuracy: 0.9566 - val_loss: 0.0860 - val_accuracy: 0.9582\n",
      "Epoch 305/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.0915 - accuracy: 0.9590 - val_loss: 0.1135 - val_accuracy: 0.9447\n",
      "Epoch 306/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0902 - accuracy: 0.9595 - val_loss: 0.1336 - val_accuracy: 0.9357\n",
      "Epoch 307/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0957 - accuracy: 0.9574 - val_loss: 0.0845 - val_accuracy: 0.9652\n",
      "Epoch 308/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.0916 - accuracy: 0.9598 - val_loss: 0.2416 - val_accuracy: 0.9111\n",
      "Epoch 309/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.0894 - accuracy: 0.9590 - val_loss: 0.2704 - val_accuracy: 0.9135\n",
      "Epoch 310/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0955 - accuracy: 0.9588 - val_loss: 0.1693 - val_accuracy: 0.9235\n",
      "Epoch 311/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0845 - accuracy: 0.9614 - val_loss: 0.0948 - val_accuracy: 0.9560\n",
      "Epoch 312/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0837 - accuracy: 0.9619 - val_loss: 0.1680 - val_accuracy: 0.9335\n",
      "Epoch 313/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0906 - accuracy: 0.9591 - val_loss: 0.1412 - val_accuracy: 0.9353\n",
      "Epoch 314/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0945 - accuracy: 0.9589 - val_loss: 0.1031 - val_accuracy: 0.9483\n",
      "Epoch 315/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0853 - accuracy: 0.9615 - val_loss: 0.0745 - val_accuracy: 0.9666\n",
      "Epoch 316/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0864 - accuracy: 0.9623 - val_loss: 0.0762 - val_accuracy: 0.9665\n",
      "Epoch 317/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0843 - accuracy: 0.9628 - val_loss: 0.1160 - val_accuracy: 0.9485\n",
      "Epoch 318/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0868 - accuracy: 0.9602 - val_loss: 0.0813 - val_accuracy: 0.9616\n",
      "Epoch 319/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0876 - accuracy: 0.9616 - val_loss: 0.1293 - val_accuracy: 0.9388\n",
      "Epoch 320/500\n",
      "31493/31493 [==============================] - 3s 92us/sample - loss: 0.0915 - accuracy: 0.9578 - val_loss: 0.0844 - val_accuracy: 0.9617\n",
      "Epoch 321/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0898 - accuracy: 0.9608 - val_loss: 0.0845 - val_accuracy: 0.9605\n",
      "Epoch 322/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0855 - accuracy: 0.9623 - val_loss: 0.1312 - val_accuracy: 0.9367\n",
      "Epoch 323/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0942 - accuracy: 0.9588 - val_loss: 0.1866 - val_accuracy: 0.9177\n",
      "Epoch 324/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0903 - accuracy: 0.9615 - val_loss: 0.0791 - val_accuracy: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0903 - accuracy: 0.9597 - val_loss: 0.1206 - val_accuracy: 0.9405\n",
      "Epoch 326/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0913 - accuracy: 0.9595 - val_loss: 0.0818 - val_accuracy: 0.9619\n",
      "Epoch 327/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0848 - accuracy: 0.9616 - val_loss: 0.2074 - val_accuracy: 0.9168\n",
      "Epoch 328/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0930 - accuracy: 0.9579 - val_loss: 0.0781 - val_accuracy: 0.9651\n",
      "Epoch 329/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0899 - accuracy: 0.9593 - val_loss: 0.0705 - val_accuracy: 0.9703\n",
      "Epoch 330/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0921 - accuracy: 0.9595 - val_loss: 0.1975 - val_accuracy: 0.9136\n",
      "Epoch 331/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0900 - accuracy: 0.9604 - val_loss: 0.0706 - val_accuracy: 0.9711\n",
      "Epoch 332/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0830 - accuracy: 0.9623 - val_loss: 0.0734 - val_accuracy: 0.9675\n",
      "Epoch 333/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0929 - accuracy: 0.9596 - val_loss: 0.1739 - val_accuracy: 0.9249\n",
      "Epoch 334/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0930 - accuracy: 0.9575 - val_loss: 0.1195 - val_accuracy: 0.9408\n",
      "Epoch 335/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0849 - accuracy: 0.9625 - val_loss: 0.0957 - val_accuracy: 0.9507\n",
      "Epoch 336/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0865 - accuracy: 0.9610 - val_loss: 0.0745 - val_accuracy: 0.9666\n",
      "Epoch 337/500\n",
      "31493/31493 [==============================] - 2s 76us/sample - loss: 0.0926 - accuracy: 0.9592 - val_loss: 0.0781 - val_accuracy: 0.9652\n",
      "Epoch 338/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0856 - accuracy: 0.9620 - val_loss: 0.1658 - val_accuracy: 0.9238\n",
      "Epoch 339/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0865 - accuracy: 0.9618 - val_loss: 0.1420 - val_accuracy: 0.9350\n",
      "Epoch 340/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0931 - accuracy: 0.9589 - val_loss: 0.1217 - val_accuracy: 0.9385\n",
      "Epoch 341/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0916 - accuracy: 0.9591 - val_loss: 0.1158 - val_accuracy: 0.9397\n",
      "Epoch 342/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0853 - accuracy: 0.9622 - val_loss: 0.0714 - val_accuracy: 0.9705\n",
      "Epoch 343/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0860 - accuracy: 0.9610 - val_loss: 0.0771 - val_accuracy: 0.9650\n",
      "Epoch 344/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0955 - accuracy: 0.9596 - val_loss: 0.0933 - val_accuracy: 0.9594\n",
      "Epoch 345/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0875 - accuracy: 0.9606 - val_loss: 0.1258 - val_accuracy: 0.9392\n",
      "Epoch 346/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0853 - accuracy: 0.9615 - val_loss: 0.0938 - val_accuracy: 0.9544\n",
      "Epoch 347/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0840 - accuracy: 0.9627 - val_loss: 0.0706 - val_accuracy: 0.9695\n",
      "Epoch 348/500\n",
      "31493/31493 [==============================] - 2s 75us/sample - loss: 0.0921 - accuracy: 0.9592 - val_loss: 0.1822 - val_accuracy: 0.9186\n",
      "Epoch 349/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0876 - accuracy: 0.9609 - val_loss: 0.1876 - val_accuracy: 0.9307\n",
      "Epoch 350/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0858 - accuracy: 0.9609 - val_loss: 0.0786 - val_accuracy: 0.9690\n",
      "Epoch 351/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0837 - accuracy: 0.9631 - val_loss: 0.1235 - val_accuracy: 0.9427\n",
      "Epoch 352/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0914 - accuracy: 0.9608 - val_loss: 0.0882 - val_accuracy: 0.9609\n",
      "Epoch 353/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0831 - accuracy: 0.9626 - val_loss: 0.1232 - val_accuracy: 0.9415\n",
      "Epoch 354/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0886 - accuracy: 0.9607 - val_loss: 0.0787 - val_accuracy: 0.9669\n",
      "Epoch 355/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0878 - accuracy: 0.9604 - val_loss: 0.0893 - val_accuracy: 0.9563\n",
      "Epoch 356/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0969 - accuracy: 0.9596 - val_loss: 0.1450 - val_accuracy: 0.9342\n",
      "Epoch 357/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0880 - accuracy: 0.9595 - val_loss: 0.1190 - val_accuracy: 0.9457\n",
      "Epoch 358/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0973 - accuracy: 0.9563 - val_loss: 0.0793 - val_accuracy: 0.9685\n",
      "Epoch 359/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0917 - accuracy: 0.9589 - val_loss: 0.1048 - val_accuracy: 0.9481\n",
      "Epoch 360/500\n",
      "31493/31493 [==============================] - 3s 97us/sample - loss: 0.0861 - accuracy: 0.9616 - val_loss: 0.0797 - val_accuracy: 0.9645\n",
      "Epoch 361/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0872 - accuracy: 0.9608 - val_loss: 0.0944 - val_accuracy: 0.9538\n",
      "Epoch 362/500\n",
      "31493/31493 [==============================] - 4s 119us/sample - loss: 0.0881 - accuracy: 0.9597 - val_loss: 0.0710 - val_accuracy: 0.9709\n",
      "Epoch 363/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0885 - accuracy: 0.9612 - val_loss: 0.0955 - val_accuracy: 0.9522\n",
      "Epoch 364/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0887 - accuracy: 0.9605 - val_loss: 0.0707 - val_accuracy: 0.9692\n",
      "Epoch 365/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0852 - accuracy: 0.9622 - val_loss: 0.1305 - val_accuracy: 0.9368\n",
      "Epoch 366/500\n",
      "31493/31493 [==============================] - 3s 92us/sample - loss: 0.0869 - accuracy: 0.9597 - val_loss: 0.2134 - val_accuracy: 0.9164\n",
      "Epoch 367/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0831 - accuracy: 0.9609 - val_loss: 0.0781 - val_accuracy: 0.9638\n",
      "Epoch 368/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0877 - accuracy: 0.9615 - val_loss: 0.1514 - val_accuracy: 0.9329\n",
      "Epoch 369/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0925 - accuracy: 0.9585 - val_loss: 0.1265 - val_accuracy: 0.9358\n",
      "Epoch 370/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0889 - accuracy: 0.9596 - val_loss: 0.0938 - val_accuracy: 0.9542\n",
      "Epoch 371/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0815 - accuracy: 0.9646 - val_loss: 0.0724 - val_accuracy: 0.9657\n",
      "Epoch 372/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0893 - accuracy: 0.9607 - val_loss: 0.0750 - val_accuracy: 0.9647\n",
      "Epoch 373/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0872 - accuracy: 0.9617 - val_loss: 0.1140 - val_accuracy: 0.9392\n",
      "Epoch 374/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0820 - accuracy: 0.9638 - val_loss: 0.0857 - val_accuracy: 0.9590\n",
      "Epoch 375/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0904 - accuracy: 0.9616 - val_loss: 0.1214 - val_accuracy: 0.9485\n",
      "Epoch 376/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0863 - accuracy: 0.9603 - val_loss: 0.0697 - val_accuracy: 0.9701\n",
      "Epoch 377/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.0819 - accuracy: 0.9631 - val_loss: 0.1419 - val_accuracy: 0.9347\n",
      "Epoch 378/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0849 - accuracy: 0.9624 - val_loss: 0.2494 - val_accuracy: 0.9121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0893 - accuracy: 0.9608 - val_loss: 0.0711 - val_accuracy: 0.9693\n",
      "Epoch 380/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.0841 - accuracy: 0.9617 - val_loss: 0.0740 - val_accuracy: 0.9677\n",
      "Epoch 381/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0876 - accuracy: 0.9601 - val_loss: 0.0742 - val_accuracy: 0.9682\n",
      "Epoch 382/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0874 - accuracy: 0.9615 - val_loss: 0.0730 - val_accuracy: 0.9665\n",
      "Epoch 383/500\n",
      "31493/31493 [==============================] - 3s 79us/sample - loss: 0.0827 - accuracy: 0.9640 - val_loss: 0.0913 - val_accuracy: 0.9574\n",
      "Epoch 384/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0816 - accuracy: 0.9637 - val_loss: 0.0887 - val_accuracy: 0.9548\n",
      "Epoch 385/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0933 - accuracy: 0.9607 - val_loss: 0.1426 - val_accuracy: 0.9400\n",
      "Epoch 386/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0852 - accuracy: 0.9621 - val_loss: 0.0707 - val_accuracy: 0.9695\n",
      "Epoch 387/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0910 - accuracy: 0.9594 - val_loss: 0.0779 - val_accuracy: 0.9674\n",
      "Epoch 388/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0900 - accuracy: 0.9606 - val_loss: 0.0792 - val_accuracy: 0.9627\n",
      "Epoch 389/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0822 - accuracy: 0.9623 - val_loss: 0.0699 - val_accuracy: 0.9711\n",
      "Epoch 390/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0834 - accuracy: 0.9633 - val_loss: 0.1443 - val_accuracy: 0.9354\n",
      "Epoch 391/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0862 - accuracy: 0.9609 - val_loss: 0.0745 - val_accuracy: 0.9670\n",
      "Epoch 392/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0823 - accuracy: 0.9640 - val_loss: 0.0726 - val_accuracy: 0.9666\n",
      "Epoch 393/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0838 - accuracy: 0.9619 - val_loss: 0.0729 - val_accuracy: 0.9673\n",
      "Epoch 394/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0847 - accuracy: 0.9633 - val_loss: 0.0846 - val_accuracy: 0.9581\n",
      "Epoch 395/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0860 - accuracy: 0.9616 - val_loss: 0.0723 - val_accuracy: 0.9672\n",
      "Epoch 396/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0838 - accuracy: 0.9630 - val_loss: 0.1011 - val_accuracy: 0.9518\n",
      "Epoch 397/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0841 - accuracy: 0.9620 - val_loss: 0.0795 - val_accuracy: 0.9621\n",
      "Epoch 398/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0777 - accuracy: 0.9652 - val_loss: 0.0986 - val_accuracy: 0.9514\n",
      "Epoch 399/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0864 - accuracy: 0.9622 - val_loss: 0.0814 - val_accuracy: 0.9630\n",
      "Epoch 400/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0838 - accuracy: 0.9627 - val_loss: 0.3157 - val_accuracy: 0.9046\n",
      "Epoch 401/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0911 - accuracy: 0.9587 - val_loss: 0.0778 - val_accuracy: 0.9695\n",
      "Epoch 402/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0851 - accuracy: 0.9620 - val_loss: 0.0979 - val_accuracy: 0.9524\n",
      "Epoch 403/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0851 - accuracy: 0.9612 - val_loss: 0.0931 - val_accuracy: 0.9537\n",
      "Epoch 404/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0848 - accuracy: 0.9625 - val_loss: 0.0804 - val_accuracy: 0.9608\n",
      "Epoch 405/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0827 - accuracy: 0.9629 - val_loss: 0.0844 - val_accuracy: 0.9615\n",
      "Epoch 406/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0823 - accuracy: 0.9632 - val_loss: 0.0709 - val_accuracy: 0.9693\n",
      "Epoch 407/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0837 - accuracy: 0.9627 - val_loss: 0.0731 - val_accuracy: 0.9695\n",
      "Epoch 408/500\n",
      "31493/31493 [==============================] - 3s 93us/sample - loss: 0.0843 - accuracy: 0.9628 - val_loss: 0.4934 - val_accuracy: 0.8772\n",
      "Epoch 409/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0851 - accuracy: 0.9621 - val_loss: 0.0957 - val_accuracy: 0.9537\n",
      "Epoch 410/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0854 - accuracy: 0.9625 - val_loss: 0.0728 - val_accuracy: 0.9681\n",
      "Epoch 411/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0819 - accuracy: 0.9626 - val_loss: 0.0755 - val_accuracy: 0.9661\n",
      "Epoch 412/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0851 - accuracy: 0.9626 - val_loss: 0.0896 - val_accuracy: 0.9566\n",
      "Epoch 413/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0797 - accuracy: 0.9642 - val_loss: 0.1482 - val_accuracy: 0.9338\n",
      "Epoch 414/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0855 - accuracy: 0.9619 - val_loss: 0.1143 - val_accuracy: 0.9435\n",
      "Epoch 415/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0918 - accuracy: 0.9588 - val_loss: 0.1045 - val_accuracy: 0.9497\n",
      "Epoch 416/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0844 - accuracy: 0.9628 - val_loss: 0.1349 - val_accuracy: 0.9347\n",
      "Epoch 417/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0847 - accuracy: 0.9618 - val_loss: 0.0826 - val_accuracy: 0.9608\n",
      "Epoch 418/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0828 - accuracy: 0.9624 - val_loss: 0.1315 - val_accuracy: 0.9354\n",
      "Epoch 419/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0866 - accuracy: 0.9616 - val_loss: 0.1747 - val_accuracy: 0.9265\n",
      "Epoch 420/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0806 - accuracy: 0.9648 - val_loss: 0.1577 - val_accuracy: 0.9500\n",
      "Epoch 421/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0813 - accuracy: 0.9640 - val_loss: 0.0813 - val_accuracy: 0.9621\n",
      "Epoch 422/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0811 - accuracy: 0.9643 - val_loss: 0.0702 - val_accuracy: 0.9702\n",
      "Epoch 423/500\n",
      "31493/31493 [==============================] - 3s 92us/sample - loss: 0.0793 - accuracy: 0.9642 - val_loss: 0.1021 - val_accuracy: 0.9506\n",
      "Epoch 424/500\n",
      "31493/31493 [==============================] - 3s 102us/sample - loss: 0.0823 - accuracy: 0.9635 - val_loss: 0.0919 - val_accuracy: 0.9557\n",
      "Epoch 425/500\n",
      "31493/31493 [==============================] - 3s 93us/sample - loss: 0.0892 - accuracy: 0.9596 - val_loss: 0.0718 - val_accuracy: 0.9674\n",
      "Epoch 426/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0825 - accuracy: 0.9632 - val_loss: 0.0934 - val_accuracy: 0.9533\n",
      "Epoch 427/500\n",
      "31493/31493 [==============================] - 3s 95us/sample - loss: 0.0849 - accuracy: 0.9617 - val_loss: 0.1924 - val_accuracy: 0.9252\n",
      "Epoch 428/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.0815 - accuracy: 0.9636 - val_loss: 0.0745 - val_accuracy: 0.9669\n",
      "Epoch 429/500\n",
      "31493/31493 [==============================] - 3s 90us/sample - loss: 0.0829 - accuracy: 0.9636 - val_loss: 0.0746 - val_accuracy: 0.9690\n",
      "Epoch 430/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.0838 - accuracy: 0.9613 - val_loss: 0.1085 - val_accuracy: 0.9472\n",
      "Epoch 431/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0862 - accuracy: 0.9615 - val_loss: 0.0783 - val_accuracy: 0.9644\n",
      "Epoch 432/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0797 - accuracy: 0.9645 - val_loss: 0.1585 - val_accuracy: 0.9327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0828 - accuracy: 0.9645 - val_loss: 0.1207 - val_accuracy: 0.9563\n",
      "Epoch 434/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0796 - accuracy: 0.9651 - val_loss: 0.1475 - val_accuracy: 0.9337\n",
      "Epoch 435/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0833 - accuracy: 0.9634 - val_loss: 0.0687 - val_accuracy: 0.9709\n",
      "Epoch 436/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0769 - accuracy: 0.9662 - val_loss: 0.0869 - val_accuracy: 0.9558\n",
      "Epoch 437/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0799 - accuracy: 0.9640 - val_loss: 0.0684 - val_accuracy: 0.9691\n",
      "Epoch 438/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0840 - accuracy: 0.9617 - val_loss: 0.0948 - val_accuracy: 0.9556\n",
      "Epoch 439/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0804 - accuracy: 0.9629 - val_loss: 0.0709 - val_accuracy: 0.9697\n",
      "Epoch 440/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0805 - accuracy: 0.9633 - val_loss: 0.0711 - val_accuracy: 0.9686\n",
      "Epoch 441/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0796 - accuracy: 0.9639 - val_loss: 0.0810 - val_accuracy: 0.9631\n",
      "Epoch 442/500\n",
      "31493/31493 [==============================] - 3s 79us/sample - loss: 0.0772 - accuracy: 0.9655 - val_loss: 0.0742 - val_accuracy: 0.9655\n",
      "Epoch 443/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0805 - accuracy: 0.9647 - val_loss: 0.0934 - val_accuracy: 0.9551\n",
      "Epoch 444/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0766 - accuracy: 0.9652 - val_loss: 0.0961 - val_accuracy: 0.9547\n",
      "Epoch 445/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0804 - accuracy: 0.9645 - val_loss: 0.1091 - val_accuracy: 0.9498\n",
      "Epoch 446/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0748 - accuracy: 0.9659 - val_loss: 0.1038 - val_accuracy: 0.9509\n",
      "Epoch 447/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0872 - accuracy: 0.9615 - val_loss: 0.0804 - val_accuracy: 0.9670\n",
      "Epoch 448/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0885 - accuracy: 0.9612 - val_loss: 0.0820 - val_accuracy: 0.9622\n",
      "Epoch 449/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0794 - accuracy: 0.9637 - val_loss: 0.0811 - val_accuracy: 0.9625\n",
      "Epoch 450/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0838 - accuracy: 0.9633 - val_loss: 0.0730 - val_accuracy: 0.9686\n",
      "Epoch 451/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0761 - accuracy: 0.9660 - val_loss: 0.0678 - val_accuracy: 0.9703\n",
      "Epoch 452/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0802 - accuracy: 0.9645 - val_loss: 0.0751 - val_accuracy: 0.9701\n",
      "Epoch 453/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0801 - accuracy: 0.9637 - val_loss: 0.0711 - val_accuracy: 0.9690\n",
      "Epoch 454/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0815 - accuracy: 0.9624 - val_loss: 0.0791 - val_accuracy: 0.9644\n",
      "Epoch 455/500\n",
      "31493/31493 [==============================] - 3s 81us/sample - loss: 0.0827 - accuracy: 0.9626 - val_loss: 0.1012 - val_accuracy: 0.9504\n",
      "Epoch 456/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0828 - accuracy: 0.9635 - val_loss: 0.0851 - val_accuracy: 0.9607\n",
      "Epoch 457/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.0764 - accuracy: 0.9653 - val_loss: 0.0678 - val_accuracy: 0.9710\n",
      "Epoch 458/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0872 - accuracy: 0.9624 - val_loss: 0.0894 - val_accuracy: 0.9573\n",
      "Epoch 459/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0829 - accuracy: 0.9642 - val_loss: 0.0874 - val_accuracy: 0.9618\n",
      "Epoch 460/500\n",
      "31493/31493 [==============================] - 3s 94us/sample - loss: 0.0753 - accuracy: 0.9661 - val_loss: 0.0782 - val_accuracy: 0.9632\n",
      "Epoch 461/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.0814 - accuracy: 0.9642 - val_loss: 0.1018 - val_accuracy: 0.9507\n",
      "Epoch 462/500\n",
      "31493/31493 [==============================] - 3s 98us/sample - loss: 0.0849 - accuracy: 0.9624 - val_loss: 0.0871 - val_accuracy: 0.9559\n",
      "Epoch 463/500\n",
      "31493/31493 [==============================] - 3s 102us/sample - loss: 0.0825 - accuracy: 0.9627 - val_loss: 0.0796 - val_accuracy: 0.9629\n",
      "Epoch 464/500\n",
      "31493/31493 [==============================] - 3s 100us/sample - loss: 0.0783 - accuracy: 0.9649 - val_loss: 0.1811 - val_accuracy: 0.9322\n",
      "Epoch 465/500\n",
      "31493/31493 [==============================] - 3s 109us/sample - loss: 0.0830 - accuracy: 0.9624 - val_loss: 0.0751 - val_accuracy: 0.9650\n",
      "Epoch 466/500\n",
      "31493/31493 [==============================] - 3s 87us/sample - loss: 0.0784 - accuracy: 0.9648 - val_loss: 0.0713 - val_accuracy: 0.9689\n",
      "Epoch 467/500\n",
      "31493/31493 [==============================] - 3s 88us/sample - loss: 0.0793 - accuracy: 0.9651 - val_loss: 0.0714 - val_accuracy: 0.9687\n",
      "Epoch 468/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0777 - accuracy: 0.9644 - val_loss: 0.0701 - val_accuracy: 0.9697\n",
      "Epoch 469/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0786 - accuracy: 0.9653 - val_loss: 0.0820 - val_accuracy: 0.9624\n",
      "Epoch 470/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.0803 - accuracy: 0.9633 - val_loss: 0.0735 - val_accuracy: 0.9640\n",
      "Epoch 471/500\n",
      "31493/31493 [==============================] - 3s 108us/sample - loss: 0.0814 - accuracy: 0.9632 - val_loss: 0.0767 - val_accuracy: 0.9633\n",
      "Epoch 472/500\n",
      "31493/31493 [==============================] - 3s 100us/sample - loss: 0.0807 - accuracy: 0.9646 - val_loss: 0.0696 - val_accuracy: 0.9702\n",
      "Epoch 473/500\n",
      "31493/31493 [==============================] - 3s 94us/sample - loss: 0.0786 - accuracy: 0.9662 - val_loss: 0.0729 - val_accuracy: 0.9666\n",
      "Epoch 474/500\n",
      "31493/31493 [==============================] - 3s 100us/sample - loss: 0.0821 - accuracy: 0.9626 - val_loss: 0.0672 - val_accuracy: 0.9720\n",
      "Epoch 475/500\n",
      "31493/31493 [==============================] - 3s 98us/sample - loss: 0.0813 - accuracy: 0.9645 - val_loss: 0.0686 - val_accuracy: 0.9683\n",
      "Epoch 476/500\n",
      "31493/31493 [==============================] - 3s 95us/sample - loss: 0.0808 - accuracy: 0.9626 - val_loss: 0.0688 - val_accuracy: 0.9714\n",
      "Epoch 477/500\n",
      "31493/31493 [==============================] - 3s 91us/sample - loss: 0.0793 - accuracy: 0.9645 - val_loss: 0.0821 - val_accuracy: 0.9608\n",
      "Epoch 478/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0799 - accuracy: 0.9637 - val_loss: 0.0773 - val_accuracy: 0.9640\n",
      "Epoch 479/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0805 - accuracy: 0.9636 - val_loss: 0.0776 - val_accuracy: 0.9617\n",
      "Epoch 480/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0818 - accuracy: 0.9638 - val_loss: 0.0679 - val_accuracy: 0.9717\n",
      "Epoch 481/500\n",
      "31493/31493 [==============================] - 3s 85us/sample - loss: 0.0812 - accuracy: 0.9648 - val_loss: 0.0753 - val_accuracy: 0.9687\n",
      "Epoch 482/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0827 - accuracy: 0.9636 - val_loss: 0.1398 - val_accuracy: 0.9364\n",
      "Epoch 483/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0762 - accuracy: 0.9648 - val_loss: 0.0692 - val_accuracy: 0.9685\n",
      "Epoch 484/500\n",
      "31493/31493 [==============================] - 3s 84us/sample - loss: 0.0776 - accuracy: 0.9656 - val_loss: 0.0901 - val_accuracy: 0.9552\n",
      "Epoch 485/500\n",
      "31493/31493 [==============================] - 3s 82us/sample - loss: 0.0790 - accuracy: 0.9640 - val_loss: 0.2835 - val_accuracy: 0.9111\n",
      "Epoch 486/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0812 - accuracy: 0.9634 - val_loss: 0.1738 - val_accuracy: 0.9275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0831 - accuracy: 0.9625 - val_loss: 0.0709 - val_accuracy: 0.9696\n",
      "Epoch 488/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0819 - accuracy: 0.9628 - val_loss: 0.0674 - val_accuracy: 0.9709\n",
      "Epoch 489/500\n",
      "31493/31493 [==============================] - 3s 89us/sample - loss: 0.0762 - accuracy: 0.9667 - val_loss: 0.0993 - val_accuracy: 0.9522\n",
      "Epoch 490/500\n",
      "31493/31493 [==============================] - 3s 86us/sample - loss: 0.0803 - accuracy: 0.9644 - val_loss: 0.0766 - val_accuracy: 0.9663\n",
      "Epoch 491/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0809 - accuracy: 0.9643 - val_loss: 0.0712 - val_accuracy: 0.9666\n",
      "Epoch 492/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0825 - accuracy: 0.9628 - val_loss: 0.0710 - val_accuracy: 0.9691\n",
      "Epoch 493/500\n",
      "31493/31493 [==============================] - 3s 83us/sample - loss: 0.0826 - accuracy: 0.9625 - val_loss: 0.0727 - val_accuracy: 0.9684\n",
      "Epoch 494/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0803 - accuracy: 0.9623 - val_loss: 0.0858 - val_accuracy: 0.9600\n",
      "Epoch 495/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0882 - accuracy: 0.9611 - val_loss: 0.0762 - val_accuracy: 0.9639\n",
      "Epoch 496/500\n",
      "31493/31493 [==============================] - 2s 77us/sample - loss: 0.0841 - accuracy: 0.9630 - val_loss: 0.0809 - val_accuracy: 0.9623\n",
      "Epoch 497/500\n",
      "31493/31493 [==============================] - 2s 79us/sample - loss: 0.0797 - accuracy: 0.9643 - val_loss: 0.0890 - val_accuracy: 0.9564\n",
      "Epoch 498/500\n",
      "31493/31493 [==============================] - 3s 80us/sample - loss: 0.0794 - accuracy: 0.9644 - val_loss: 0.0741 - val_accuracy: 0.9670\n",
      "Epoch 499/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0830 - accuracy: 0.9631 - val_loss: 0.0863 - val_accuracy: 0.9601\n",
      "Epoch 500/500\n",
      "31493/31493 [==============================] - 2s 78us/sample - loss: 0.0780 - accuracy: 0.9649 - val_loss: 0.0757 - val_accuracy: 0.9631\n",
      "Wall time: 21min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history=model.fit(X_train, y_train_np, epochs=500, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150 neuronas, adam, he unifrom, dropout 0, batch 128, lr=0.001: 0.9651,0.9649\n",
    "\n",
    "# con nadam hay demasiado ruido, asi que lo descarto\n",
    "\n",
    "# 150 neuronas, adam, GLOROT unifrom, dropout 0, batch 128, lr=0.001: 0.9676,0.9713\n",
    "\n",
    "# 250 neuronas, adam, GLOROT unifrom, dropout 0, batch 128, lr=0.001: 0.9630,0.9685\n",
    "# 150 neuronas, adam, GLOROT unifrom, dropout 0.1, batch 0, lr=0.001: 0.95,0.94\n",
    "# 150 neuronas, adam, GLOROT unifrom, dropout 0, batch 128, lr=0.0001: 0.9649,0.9631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10498/10498 [==============================] - 0s 33us/sample - loss: 0.0757 - accuracy: 0.9631\n",
      "0.96313584\n",
      "[[2108    9    6    0    0]\n",
      " [   0 2086   40    8   10]\n",
      " [   0    5 1911  128   29]\n",
      " [   0    0   55 1916   87]\n",
      " [   0    0    4    6 2090]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00      2123\n",
      "         1.0       0.99      0.97      0.98      2144\n",
      "         2.0       0.95      0.92      0.93      2073\n",
      "         3.0       0.93      0.93      0.93      2058\n",
      "         4.0       0.94      1.00      0.97      2100\n",
      "\n",
      "    accuracy                           0.96     10498\n",
      "   macro avg       0.96      0.96      0.96     10498\n",
      "weighted avg       0.96      0.96      0.96     10498\n",
      "\n",
      "0.9631358353972185\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test_np)\n",
    "# print(val_loss)\n",
    "print(val_acc)\n",
    "#model.summary()\n",
    "#model.get_config()\n",
    "#model.get_weights()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "y_pred= model.predict_classes(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1=history\n",
    "# plot learning curves\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Accuracy')\n",
    "# pyplot.plot(history.history['loss'], label='train')\n",
    "# pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shouls chage\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hidden_layers=3,neurons=128,optimizer='adam',learn_rate=0.001, init_mode='he_normal', activation='relu', dropout_rate=0.0, weight_constraint=0):#parameters here are default\n",
    "    #create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #los weight_initializer son mas optimos dependiendo de la funcion de activacion\n",
    "    \n",
    "    for i in range(hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(neurons, kernel_initializer=init_mode, activation=activation))\n",
    "        #     model.add(BatchNormalization())     , use_bias=False\n",
    "        #     model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(5, activation='softmax'))\n",
    "    \n",
    "    #aqui estoy obligando a que el optimizer sea adam. Deberia decir: if optimizer=='adam' then... y hacerlo para otros optimizadores\n",
    "    #optimizer = tf.keras.optimizers.Adam(learning_rate=learn_rate, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    #compile model        https://keras.io/models/model/\n",
    "    model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31493 samples, validate on 10498 samples\n",
      "Epoch 1/5\n",
      "31493/31493 [==============================] - 1s 43us/sample - loss: 1.1172 - accuracy: 0.5438 - val_loss: 0.8206 - val_accuracy: 0.6878\n",
      "Epoch 2/5\n",
      "31493/31493 [==============================] - 1s 19us/sample - loss: 0.7179 - accuracy: 0.7442 - val_loss: 0.7060 - val_accuracy: 0.6987\n",
      "Epoch 3/5\n",
      "31493/31493 [==============================] - 1s 17us/sample - loss: 0.5983 - accuracy: 0.7724 - val_loss: 0.6925 - val_accuracy: 0.6959\n",
      "Epoch 4/5\n",
      "31493/31493 [==============================] - 1s 19us/sample - loss: 0.4978 - accuracy: 0.8263 - val_loss: 0.4609 - val_accuracy: 0.8626\n",
      "Epoch 5/5\n",
      "31493/31493 [==============================] - 1s 28us/sample - loss: 0.4503 - accuracy: 0.8319 - val_loss: 0.4211 - val_accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train_np, epochs=5, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=25, batch_size=64, verbose=1) #if I add any param here has to be in the model(there has to be a default value)#de values that I set here are definitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS  SI QUIERO CUALQUIER PARAMETRO QUE NO SEA EL DEFAULT LO PONGO AQUI ABAJO\n",
    "batch_size = [128]#[128,264]\n",
    "epochs = [500]\n",
    "optimizer = ['Adam']#['Nadam','Adagrad','SGD', 'RMSprop', 'Adagrad', 'Adadelta',  'Adamax', 'Nadam']\n",
    "learn_rate = [0.01,0.001,0.0001]#[0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0]#[0.0, 0.2, 0.4, 0.6, 0.8, 0.9]  #en este caso momentum es para SGD por ej., para adam solo se usa learn. rate\n",
    "activation = ['relu']#['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "init_mode = ['glorot_uniform','glorot_normal' ,'lecun_uniform']#['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "weight_constraint = [0]#[1, 2, 3, 4, 5]\n",
    "dropout_rate =[0,0.1,0.2] #[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "neurons = [150,2300] #[5, 10, 15, 20, 25, 30]\n",
    "hidden_layers= [5,25,100]\n",
    "\n",
    "param_grid = dict(epochs=epochs, optimizer=optimizer, init_mode=init_mode, neurons=neurons, hidden_layers=hidden_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#FIT GRID SEARCH\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "#FIT RANDOM GRID SEARCH\n",
    "#grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_jobs=-1, cv=2)\n",
    "grid_result = grid.fit(X_train, y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# means = grid_result.cv_results_['mean_test_score']\n",
    "# stds = grid_result.cv_results_['std_test_score']\n",
    "# params = grid_result.cv_results_['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid_result.cv_results_)\n",
    "results.to_csv('random-grid-search-results-03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_epochs</th>\n",
       "      <th>param_hidden_layers</th>\n",
       "      <th>param_init_mode</th>\n",
       "      <th>param_neurons</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1109.592887</td>\n",
       "      <td>290.070685</td>\n",
       "      <td>0.802189</td>\n",
       "      <td>0.270133</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>20</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 3, 'init_mode...</td>\n",
       "      <td>0.965074</td>\n",
       "      <td>0.962375</td>\n",
       "      <td>0.959835</td>\n",
       "      <td>0.912829</td>\n",
       "      <td>0.958082</td>\n",
       "      <td>0.951639</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>561.664953</td>\n",
       "      <td>23.897963</td>\n",
       "      <td>1.021259</td>\n",
       "      <td>0.150457</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 3, 'init_mode...</td>\n",
       "      <td>0.972377</td>\n",
       "      <td>0.969201</td>\n",
       "      <td>0.966344</td>\n",
       "      <td>0.965703</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.968279</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655.796698</td>\n",
       "      <td>37.961556</td>\n",
       "      <td>1.177274</td>\n",
       "      <td>0.219627</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 3, 'init_mode...</td>\n",
       "      <td>0.912526</td>\n",
       "      <td>0.966661</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.956975</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>960.244581</td>\n",
       "      <td>36.629968</td>\n",
       "      <td>1.261204</td>\n",
       "      <td>0.289866</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 3, 'init_mode...</td>\n",
       "      <td>0.962216</td>\n",
       "      <td>0.971900</td>\n",
       "      <td>0.936974</td>\n",
       "      <td>0.964909</td>\n",
       "      <td>0.950619</td>\n",
       "      <td>0.957324</td>\n",
       "      <td>0.012272</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>560.450812</td>\n",
       "      <td>10.908165</td>\n",
       "      <td>1.001961</td>\n",
       "      <td>0.084071</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>20</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 5, 'init_mode...</td>\n",
       "      <td>0.967138</td>\n",
       "      <td>0.940943</td>\n",
       "      <td>0.941896</td>\n",
       "      <td>0.967609</td>\n",
       "      <td>0.965068</td>\n",
       "      <td>0.956531</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>706.382032</td>\n",
       "      <td>41.763330</td>\n",
       "      <td>1.068717</td>\n",
       "      <td>0.166672</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 5, 'init_mode...</td>\n",
       "      <td>0.961105</td>\n",
       "      <td>0.961105</td>\n",
       "      <td>0.969360</td>\n",
       "      <td>0.922198</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.956752</td>\n",
       "      <td>0.017698</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>867.139716</td>\n",
       "      <td>47.199211</td>\n",
       "      <td>1.573992</td>\n",
       "      <td>0.158567</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 5, 'init_mode...</td>\n",
       "      <td>0.965074</td>\n",
       "      <td>0.966661</td>\n",
       "      <td>0.969360</td>\n",
       "      <td>0.971737</td>\n",
       "      <td>0.958717</td>\n",
       "      <td>0.966310</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1376.488315</td>\n",
       "      <td>71.903676</td>\n",
       "      <td>1.576278</td>\n",
       "      <td>0.337862</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 5, 'init_mode...</td>\n",
       "      <td>0.970154</td>\n",
       "      <td>0.969836</td>\n",
       "      <td>0.971583</td>\n",
       "      <td>0.971896</td>\n",
       "      <td>0.968244</td>\n",
       "      <td>0.970343</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>811.482436</td>\n",
       "      <td>18.104846</td>\n",
       "      <td>1.449373</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>20</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 10, 'init_mod...</td>\n",
       "      <td>0.936974</td>\n",
       "      <td>0.929830</td>\n",
       "      <td>0.968249</td>\n",
       "      <td>0.960622</td>\n",
       "      <td>0.942998</td>\n",
       "      <td>0.947735</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>940.923867</td>\n",
       "      <td>61.930587</td>\n",
       "      <td>1.665412</td>\n",
       "      <td>0.195899</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 10, 'init_mod...</td>\n",
       "      <td>0.968725</td>\n",
       "      <td>0.927290</td>\n",
       "      <td>0.966503</td>\n",
       "      <td>0.946015</td>\n",
       "      <td>0.913147</td>\n",
       "      <td>0.944336</td>\n",
       "      <td>0.021690</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1293.260508</td>\n",
       "      <td>77.580263</td>\n",
       "      <td>2.526580</td>\n",
       "      <td>0.492179</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 10, 'init_mod...</td>\n",
       "      <td>0.959359</td>\n",
       "      <td>0.962057</td>\n",
       "      <td>0.963645</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.956970</td>\n",
       "      <td>0.961325</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2393.898562</td>\n",
       "      <td>251.735974</td>\n",
       "      <td>2.655394</td>\n",
       "      <td>0.568615</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 10, 'init_mod...</td>\n",
       "      <td>0.942531</td>\n",
       "      <td>0.962375</td>\n",
       "      <td>0.963645</td>\n",
       "      <td>0.954271</td>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.951608</td>\n",
       "      <td>0.011126</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1091.429347</td>\n",
       "      <td>52.205370</td>\n",
       "      <td>2.203560</td>\n",
       "      <td>0.509760</td>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>20</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 15, 'init_mod...</td>\n",
       "      <td>0.967296</td>\n",
       "      <td>0.940467</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.962528</td>\n",
       "      <td>0.963480</td>\n",
       "      <td>0.960341</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1199.188012</td>\n",
       "      <td>73.757949</td>\n",
       "      <td>2.116400</td>\n",
       "      <td>0.223170</td>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>50</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 15, 'init_mod...</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>0.938244</td>\n",
       "      <td>0.963328</td>\n",
       "      <td>0.948555</td>\n",
       "      <td>0.907431</td>\n",
       "      <td>0.941002</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1720.248497</td>\n",
       "      <td>116.978699</td>\n",
       "      <td>3.087835</td>\n",
       "      <td>0.830405</td>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>100</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 15, 'init_mod...</td>\n",
       "      <td>0.956025</td>\n",
       "      <td>0.954755</td>\n",
       "      <td>0.946817</td>\n",
       "      <td>0.954112</td>\n",
       "      <td>0.949031</td>\n",
       "      <td>0.952148</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3060.602484</td>\n",
       "      <td>790.481521</td>\n",
       "      <td>2.589491</td>\n",
       "      <td>1.563536</td>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>he_uniform</td>\n",
       "      <td>150</td>\n",
       "      <td>Adam</td>\n",
       "      <td>{'epochs': 500, 'hidden_layers': 15, 'init_mod...</td>\n",
       "      <td>0.954437</td>\n",
       "      <td>0.957295</td>\n",
       "      <td>0.964439</td>\n",
       "      <td>0.938393</td>\n",
       "      <td>0.949349</td>\n",
       "      <td>0.952783</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_epochs  \\\n",
       "0     1109.592887    290.070685         0.802189        0.270133          500   \n",
       "1      561.664953     23.897963         1.021259        0.150457          500   \n",
       "2      655.796698     37.961556         1.177274        0.219627          500   \n",
       "3      960.244581     36.629968         1.261204        0.289866          500   \n",
       "4      560.450812     10.908165         1.001961        0.084071          500   \n",
       "5      706.382032     41.763330         1.068717        0.166672          500   \n",
       "6      867.139716     47.199211         1.573992        0.158567          500   \n",
       "7     1376.488315     71.903676         1.576278        0.337862          500   \n",
       "8      811.482436     18.104846         1.449373        0.081629          500   \n",
       "9      940.923867     61.930587         1.665412        0.195899          500   \n",
       "10    1293.260508     77.580263         2.526580        0.492179          500   \n",
       "11    2393.898562    251.735974         2.655394        0.568615          500   \n",
       "12    1091.429347     52.205370         2.203560        0.509760          500   \n",
       "13    1199.188012     73.757949         2.116400        0.223170          500   \n",
       "14    1720.248497    116.978699         3.087835        0.830405          500   \n",
       "15    3060.602484    790.481521         2.589491        1.563536          500   \n",
       "\n",
       "   param_hidden_layers param_init_mode param_neurons param_optimizer  \\\n",
       "0                    3      he_uniform            20            Adam   \n",
       "1                    3      he_uniform            50            Adam   \n",
       "2                    3      he_uniform           100            Adam   \n",
       "3                    3      he_uniform           150            Adam   \n",
       "4                    5      he_uniform            20            Adam   \n",
       "5                    5      he_uniform            50            Adam   \n",
       "6                    5      he_uniform           100            Adam   \n",
       "7                    5      he_uniform           150            Adam   \n",
       "8                   10      he_uniform            20            Adam   \n",
       "9                   10      he_uniform            50            Adam   \n",
       "10                  10      he_uniform           100            Adam   \n",
       "11                  10      he_uniform           150            Adam   \n",
       "12                  15      he_uniform            20            Adam   \n",
       "13                  15      he_uniform            50            Adam   \n",
       "14                  15      he_uniform           100            Adam   \n",
       "15                  15      he_uniform           150            Adam   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'epochs': 500, 'hidden_layers': 3, 'init_mode...           0.965074   \n",
       "1   {'epochs': 500, 'hidden_layers': 3, 'init_mode...           0.972377   \n",
       "2   {'epochs': 500, 'hidden_layers': 3, 'init_mode...           0.912526   \n",
       "3   {'epochs': 500, 'hidden_layers': 3, 'init_mode...           0.962216   \n",
       "4   {'epochs': 500, 'hidden_layers': 5, 'init_mode...           0.967138   \n",
       "5   {'epochs': 500, 'hidden_layers': 5, 'init_mode...           0.961105   \n",
       "6   {'epochs': 500, 'hidden_layers': 5, 'init_mode...           0.965074   \n",
       "7   {'epochs': 500, 'hidden_layers': 5, 'init_mode...           0.970154   \n",
       "8   {'epochs': 500, 'hidden_layers': 10, 'init_mod...           0.936974   \n",
       "9   {'epochs': 500, 'hidden_layers': 10, 'init_mod...           0.968725   \n",
       "10  {'epochs': 500, 'hidden_layers': 10, 'init_mod...           0.959359   \n",
       "11  {'epochs': 500, 'hidden_layers': 10, 'init_mod...           0.942531   \n",
       "12  {'epochs': 500, 'hidden_layers': 15, 'init_mod...           0.967296   \n",
       "13  {'epochs': 500, 'hidden_layers': 15, 'init_mod...           0.947452   \n",
       "14  {'epochs': 500, 'hidden_layers': 15, 'init_mod...           0.956025   \n",
       "15  {'epochs': 500, 'hidden_layers': 15, 'init_mod...           0.954437   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.962375           0.959835           0.912829   \n",
       "1            0.969201           0.966344           0.965703   \n",
       "2            0.966661           0.967931           0.967768   \n",
       "3            0.971900           0.936974           0.964909   \n",
       "4            0.940943           0.941896           0.967609   \n",
       "5            0.961105           0.969360           0.922198   \n",
       "6            0.966661           0.969360           0.971737   \n",
       "7            0.969836           0.971583           0.971896   \n",
       "8            0.929830           0.968249           0.960622   \n",
       "9            0.927290           0.966503           0.946015   \n",
       "10           0.962057           0.963645           0.964592   \n",
       "11           0.962375           0.963645           0.954271   \n",
       "12           0.940467           0.967931           0.962528   \n",
       "13           0.938244           0.963328           0.948555   \n",
       "14           0.954755           0.946817           0.954112   \n",
       "15           0.957295           0.964439           0.938393   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.958082         0.951639        0.019548               12  \n",
       "1            0.967768         0.968279        0.002378                2  \n",
       "2            0.969990         0.956975        0.022251                7  \n",
       "3            0.950619         0.957324        0.012272                6  \n",
       "4            0.965068         0.956531        0.012372                9  \n",
       "5            0.969990         0.956752        0.017698                8  \n",
       "6            0.958717         0.966310        0.004429                3  \n",
       "7            0.968244         0.970343        0.001315                1  \n",
       "8            0.942998         0.947735        0.014462               14  \n",
       "9            0.913147         0.944336        0.021690               15  \n",
       "10           0.956970         0.961325        0.002808                4  \n",
       "11           0.935217         0.951608        0.011126               13  \n",
       "12           0.963480         0.960341        0.010155                5  \n",
       "13           0.907431         0.941002        0.018610               16  \n",
       "14           0.949031         0.952148        0.003573               11  \n",
       "15           0.949349         0.952783        0.008693               10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "results = pd.read_csv('random-grid-search-results-02.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves\n",
    "pyplot.title('accuracy')\n",
    "pyplot.xlabel('hyperparameter')\n",
    "pyplot.ylabel('Score')\n",
    "pyplot.scatter(results['param_hidden_layers'],results['mean_test_score'] )\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
